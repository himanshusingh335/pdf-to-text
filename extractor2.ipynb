{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "#import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly configure the API key here\n",
    "API_KEY = \"AIzaSyAOVRcmchMjVpUxZqH21bPvmOuhxePW3Ps\"  # Replace with your Gemini API key\n",
    "\n",
    "# Configure the Gemini API with the provided API key\n",
    "genai.configure(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_pdf(pdf_path, output_folder):\n",
    "    \"\"\"Extract embedded images and render pages with optimized bounding boxes.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    # Create separate folders for different types of images\n",
    "    embedded_images_folder = os.path.join(output_folder, \"embedded_images\")\n",
    "    rendered_images_folder = os.path.join(output_folder, \"rendered_images\")\n",
    "    region_images_folder = os.path.join(output_folder, \"region_images\")\n",
    "\n",
    "    os.makedirs(embedded_images_folder, exist_ok=True)\n",
    "    os.makedirs(rendered_images_folder, exist_ok=True)\n",
    "    os.makedirs(region_images_folder, exist_ok=True)\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        print(f\"Found {len(image_list)} embedded images on page {page_num + 1}\")\n",
    "\n",
    "        # Extract and save embedded images\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            img_extension = base_image[\"ext\"]\n",
    "            img_path = os.path.join(embedded_images_folder, f\"page_{page_num + 1}_img_{img_index + 1}.{img_extension}\")\n",
    "\n",
    "            with open(img_path, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "            print(f\"Saved embedded image: {img_path}\")\n",
    "\n",
    "        # Render page and detect regions\n",
    "        page_image_path = os.path.join(rendered_images_folder, f\"page_{page_num + 1}_rendered.png\")\n",
    "        render_page_as_image(page, page_image_path)\n",
    "\n",
    "        detect_and_save_regions(page_image_path, region_images_folder, page_num)\n",
    "\n",
    "    doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_page_as_image(page, output_path, zoom=2):\n",
    "    \"\"\"Renders a PDF page to a PNG image.\"\"\"\n",
    "    mat = fitz.Matrix(zoom, zoom)  # Higher zoom for better resolution\n",
    "    pix = page.get_pixmap(matrix=mat)\n",
    "    pix.save(output_path)\n",
    "    print(f\"Rendered page saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_page_as_image(page, output_path, zoom=2):\n",
    "    \"\"\"Renders a PDF page to a PNG image.\"\"\"\n",
    "    mat = fitz.Matrix(zoom, zoom)  # Higher zoom for better resolution\n",
    "    pix = page.get_pixmap(matrix=mat)\n",
    "    pix.save(output_path)\n",
    "    print(f\"Rendered page saved: {output_path}\")\n",
    "\n",
    "def detect_and_save_regions(image_path, output_folder, page_num):\n",
    "    \"\"\"Detects tables/charts, saves them as separate images, and annotates the page.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Adaptive thresholding to highlight tables/charts\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "\n",
    "    # Use dilation to connect close components and remove noise\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Prepare the annotated image\n",
    "    annotated_img = img.copy()\n",
    "\n",
    "    for idx, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        # Adjust the size of the bounding box to capture nearby text\n",
    "        padding = 10  # Increase bounding box size slightly\n",
    "        x, y = max(x - padding, 0), max(y - padding, 0)\n",
    "        w, h = min(w + 2 * padding, img.shape[1] - x), min(h + 2 * padding, img.shape[0] - y)\n",
    "\n",
    "        # Filter out small regions that are likely noise\n",
    "        if w > 100 and h > 100:  # Adjust size thresholds as needed\n",
    "            # Draw red bounding box\n",
    "            cv2.rectangle(annotated_img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "            # Save each detected region as a separate image\n",
    "            detected_region = img[y:y+h, x:x+w]\n",
    "            region_path = os.path.join(output_folder, f\"page_{page_num + 1}_region_{idx + 1}.png\")\n",
    "            cv2.imwrite(region_path, detected_region)\n",
    "            print(f\"Saved detected region: {region_path}\")\n",
    "\n",
    "    # Save the annotated image with all bounding boxes\n",
    "    annotated_images_folder = os.path.join(output_folder, \"annotated_images\")\n",
    "    os.makedirs(annotated_images_folder, exist_ok=True)\n",
    "    annotated_path = os.path.join(annotated_images_folder, f\"page_{page_num + 1}_annotated.png\")\n",
    "    cv2.imwrite(annotated_path, annotated_img)\n",
    "    print(f\"Annotated image saved: {annotated_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_chart_with_gemini(image_path, api_key=\"your_actual_api_key\"):\n",
    "    \"\"\"\n",
    "    Analyzes a chart image using the Gemini model.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): The path to the image file to be analyzed.\n",
    "        api_key (str): Your Gemini API key (default is a placeholder).\n",
    "        \n",
    "    Returns:\n",
    "        str: The description and data points from the chart.\n",
    "    \"\"\"\n",
    "    # Configure the Gemini API with the provided API key\n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "    def upload_to_gemini(path, mime_type=\"image/png\"):\n",
    "        \"\"\"Uploads the specified file to the Gemini model.\n",
    "        \n",
    "        Args:\n",
    "            path (str): The path to the file to be uploaded.\n",
    "            mime_type (str): The MIME type of the file. Default is 'image/png'.\n",
    "            \n",
    "        Returns:\n",
    "            file: The uploaded file object.\n",
    "        \"\"\"\n",
    "        file = genai.upload_file(path, mime_type=mime_type)\n",
    "        print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "        return file\n",
    "\n",
    "    # Configuration for the generative model\n",
    "    generation_config = {\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 64,\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    }\n",
    "\n",
    "    # Create the generative model instance\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-flash\",\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "\n",
    "    # Upload the image file to Gemini\n",
    "    image_file = upload_to_gemini(image_path, mime_type=\"image/png\")\n",
    "\n",
    "    # Start a chat session with the model\n",
    "    chat_session = model.start_chat(\n",
    "        history=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [\n",
    "                    image_file,  # The uploaded image file\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Send a message to the model for analysis\n",
    "    response = chat_session.send_message(\"Describe what the chart is about in one line and provide all the data points.\")\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "def process_images_in_folder(folder_path, api_key=\"your_actual_api_key\"):\n",
    "    \"\"\"\n",
    "    Processes all images in the specified folder using the Gemini model.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing images.\n",
    "        api_key (str): Your Gemini API key (default is a placeholder).\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"The folder {folder_path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Loop through all files in the specified folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file is an image (PNG format)\n",
    "        if filename.lower().endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Processing image: {image_path}\")\n",
    "            result = analyze_chart_with_gemini(image_path, api_key=api_key)\n",
    "            print(f\"Result for {filename}: {result}\\n\")\n",
    "            with open(\"gemini_response.txt\", \"a\") as file:\n",
    "                file.write(f\"Result for {filename}: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 embedded images on page 1\n",
      "Saved embedded image: extracted_images/embedded_images/page_1_img_1.png\n",
      "Rendered page saved: extracted_images/rendered_images/page_1_rendered.png\n",
      "Saved detected region: extracted_images/region_images/page_1_region_2.png\n",
      "Saved detected region: extracted_images/region_images/page_1_region_7.png\n",
      "Saved detected region: extracted_images/region_images/page_1_region_11.png\n",
      "Annotated image saved: extracted_images/region_images/annotated_images/page_1_annotated.png\n",
      "Processing image: extracted_images/region_images/page_1_region_2.png\n",
      "Uploaded file 'page_1_region_2.png' as: https://generativelanguage.googleapis.com/v1beta/files/gswvz5y6uo2j\n",
      "Result for page_1_region_2.png: The chart compares the budget and expenditure for different spending categories, with data points as follows: Auto - Budget: 200, Expenditure: 200; Entertainment - Budget: 2000, Expenditure: 2000; Food - Budget: 4000, Expenditure: 1000; Home - Budget: 18000, Expenditure: 18000; Medical - Budget: 0, Expenditure: 0; Personal Items - Budget: 0, Expenditure: 0; Travel - Budget: 1000, Expenditure: 1000; Utilities - Budget: 1000, Expenditure: 1000. \n",
      "\n",
      "\n",
      "Processing image: extracted_images/region_images/page_1_region_7.png\n",
      "Uploaded file 'page_1_region_7.png' as: https://generativelanguage.googleapis.com/v1beta/files/t0e8oosw92k4\n",
      "Result for page_1_region_7.png: The chart shows the population of India, China, and Russia, with India having the highest population at 1.4 billion, followed by China at 1.4 billion, and Russia at 146 million.\n",
      "\n",
      "Processing image: extracted_images/region_images/page_1_region_11.png\n",
      "Uploaded file 'page_1_region_11.png' as: https://generativelanguage.googleapis.com/v1beta/files/i3j0ymutxrow\n",
      "Result for page_1_region_11.png: The chart shows the amount of something in different countries.  India: 150123, China: 123494, Russia: 43948. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"test5.pdf\"  # Replace with your PDF path\n",
    "    output_folder = \"extracted_images\"\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Extract and annotate images from the PDF\n",
    "    extract_images_from_pdf(pdf_path, output_folder)\n",
    "    # Specify the folder containing the extracted images\n",
    "    output_folder2 = os.path.join(output_folder, \"region_images\")\n",
    "\n",
    "    # Process all images in the region_images folder\n",
    "    with open(\"key.txt\", \"r\") as key_file:\n",
    "        api_key = key_file.read().strip()\n",
    "    process_images_in_folder(output_folder2, api_key=api_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
